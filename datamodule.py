# -*- coding: utf-8 -*-
"""datamodule.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iC6F1hIZlj06UDRfsrE2vZQTJYiO1hP-
"""

import os
import h5py
import pandas as pd
import torch
import numpy as np
import pytorch_lightning as pl
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms

# -------------------------------------------------------------------
# 1. Custom Transform: NumpyCHWToPIL
# -------------------------------------------------------------------
class NumpyCHWToPIL:
    """
    Converts a numpy array of shape (C, H, W) with float values [0, 1]
    into a PIL Image, which is required for standard torchvision transforms.
    """
    def __call__(self, img_np):
        # img_np is (C, H, W). Transpose to (H, W, C) for PIL.
        img_hwc = np.transpose(img_np, (1, 2, 0))
        # Convert to uint8, scaling [0, 1] to [0, 255]
        img_uint8 = (img_hwc * 255).astype(np.uint8)
        return transforms.ToPILImage()(img_uint8)

# -------------------------------------------------------------------
# 2. DashGazeDataset
# -------------------------------------------------------------------
class DashGazeDataset(Dataset):
    """
    Reads data from HDF5 (images) and CSV (labels/landmarks).
    Returns a dictionary containing raw numpy images and label tensors.
    """
    def __init__(self, hdf5_path, csv_path):
        self.hdf = h5py.File(hdf5_path, "r")
        self.csv = pd.read_csv(csv_path)

        # Exact landmark columns from your notebook
        self.landmark_cols = [
            'face x', 'face y', 'leye x', 'leye y', 'reye x', 'reye y',
            'leye x mark', 'leye y mark', 'reye x mark', 'reye y mark',
            'nose x mark', 'nose y mark', 'lmouth x mark', 'lmouth y mark',
            'rmouth x mark', 'rmouth y mark', 'yaw_new', 'pitch_new', 'roll_new'
        ]

    def __len__(self):
        return len(self.csv)

    def __getitem__(self, idx):
        # Read Images (numpy arrays, float32, C, H, W) directly from HDF5
        driver_img = self.hdf["img"][idx]
        face_img = self.hdf["face"][idx]
        leye_img = self.hdf["leye"][idx]
        reye_img = self.hdf["reye"][idx]

        # Read Labels from CSV
        dash_gaze_x = self.csv.iloc[idx]["dash gaze x [px]"]
        dash_gaze_y = self.csv.iloc[idx]["dash gaze y [px]"]
        azimuth = self.csv.iloc[idx]["azimuth [deg]"]
        elevation = self.csv.iloc[idx]["elevation [deg]"]

        # Extract landmark coordinates
        landmarks_np = self.csv.iloc[idx][self.landmark_cols].values.astype(np.float32)

        # Convert labels to PyTorch Tensors
        gaze_loc = torch.tensor([dash_gaze_x, dash_gaze_y], dtype=torch.float32)
        gaze_ang = torch.tensor([azimuth, elevation], dtype=torch.float32)

        sample = {
            "driver_img_np": driver_img, # Kept as numpy to be processed by TransformSubset
            "face_img_np": face_img,
            "leye_img_np": leye_img,
            "reye_img_np": reye_img,
            "gaze_loc": gaze_loc,
            "gaze_ang": gaze_ang,
            "landmarks_np": landmarks_np
        }
        return sample

    def __del__(self):
        # Close the HDF5 file safely
        if hasattr(self, 'hdf') and self.hdf is not None:
            self.hdf.close()

# -------------------------------------------------------------------
# 3. TransformSubset
# -------------------------------------------------------------------
class TransformSubset(Dataset):
    """
    Wrapper to apply transforms to subsets created by random_split.
    It converts the numpy images from the parent dataset into Tensors.
    """
    def __init__(self, subset, transform=None):
        self.subset = subset
        self.transform = transform

    def __getitem__(self, idx):
        # Get item from the underlying dataset
        sample = self.subset[idx]

        # Apply transform only to the 'face' image (Augmentation/Resize)
        if self.transform:
            sample['face'] = self.transform(sample['face_img_np'])
        else:
            # If no transform, directly convert to tensor
            sample['face'] = torch.from_numpy(sample['face_img_np']).float()

        # NOTE: Driver, Left Eye, and Right Eye are NOT transformed/resized here.
        # They are converted directly to float tensors.
        sample['driver'] = torch.from_numpy(sample['driver_img_np']).float()
        sample['leye'] = torch.from_numpy(sample['leye_img_np']).float()
        sample['reye'] = torch.from_numpy(sample['reye_img_np']).float()

        # Convert landmarks to tensor
        sample['landmarks'] = torch.from_numpy(sample['landmarks_np']).float()

        # Cleanup numpy arrays to save memory
        del sample['driver_img_np']
        del sample['face_img_np']
        del sample['leye_img_np']
        del sample['reye_img_np']
        del sample['landmarks_np']

        return sample

    def __len__(self):
        return len(self.subset)

# -------------------------------------------------------------------
# 4. DashGazeDataModule
# -------------------------------------------------------------------
class DashGazeDataModule(pl.LightningDataModule):
    def __init__(self, hdf5_path, csv_path, batch_size: int = 32):
        super().__init__()
        self.hdf5_path = hdf5_path
        self.csv_path = csv_path
        self.batch_size = batch_size

        # Optimize worker count based on CPU cores
        self.num_workers = os.cpu_count() // 2 if os.cpu_count() else 1
        if self.num_workers < 1: self.num_workers = 1

        # Train Transforms (Augmentation) -> Applied to FACE only
        self.train_transforms = transforms.Compose([
            NumpyCHWToPIL(),
            transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1)], p=0.5),
            transforms.RandomResizedCrop(size=224, scale=(0.9, 1.0), ratio=(0.75, 1.333)),
            transforms.ToTensor(),
        ])

        # Validation/Test Transforms (Resize only) -> Applied to FACE only
        self.val_test_transforms = transforms.Compose([
            NumpyCHWToPIL(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

        self.dashgaze_full = None
        self.dashgaze_train = None
        self.dashgaze_val = None
        self.dashgaze_test = None

    def setup(self, stage=None):
        if self.dashgaze_full is None:
            self.dashgaze_full = DashGazeDataset(self.hdf5_path, self.csv_path)

        total_len = len(self.dashgaze_full)
        train_len = int(0.8 * total_len)
        val_len = int(0.1 * total_len)
        test_len = total_len - train_len - val_len

        # 80/10/10 Split
        train_subset, val_subset, test_subset = random_split(
            self.dashgaze_full, [train_len, val_len, test_len],
            generator=torch.Generator().manual_seed(42)
        )

        # Wrap with transforms
        self.dashgaze_train = TransformSubset(train_subset, self.train_transforms)
        self.dashgaze_val = TransformSubset(val_subset, self.val_test_transforms)
        self.dashgaze_test = TransformSubset(test_subset, self.val_test_transforms)

    def train_dataloader(self):
        return DataLoader(
            self.dashgaze_train,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=self.num_workers,
            persistent_workers=True
        )

    def val_dataloader(self):
        return DataLoader(
            self.dashgaze_val,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            persistent_workers=True
        )

    def test_dataloader(self):
        return DataLoader(
            self.dashgaze_test,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            persistent_workers=True
        )